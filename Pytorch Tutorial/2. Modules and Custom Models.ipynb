{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial\n",
    "\n",
    "### 2. Modules and Custom Models\n",
    "\n",
    "- Adding predefined modules from ```torch.nn``` to ```torch.nn.Sequential```.\n",
    "- Creating custom models by inheriting ```torch.nn.Module```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some setup.\n",
    "\n",
    "```torch.nn``` is conventionally imported as ```nn```.  \n",
    "```torch.nn.functional``` is conventionally imported as ```F```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ```torch.nn``` modules and ```torch.nn.Sequential```\n",
    "\n",
    "There are many predefined layers in ```torch.nn```, like conv, linear, pool, ReLU, and more. Also, there are many predefined functions in ```torch.nn.functional```, which overlap a lot with those in ```torch.nn```. The functions are listed in [the Pytorch documentation](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "The difference is that those defined in ```torch.nn``` are essentially wrappers of functions in ```torch.nn.functional``` plus weight initialization and functions such as ```train()```, ```eval()```, or ```parameters()```. Functionals only compute the bare computation of the layer.\n",
    "\n",
    "Here we instantiate a simple two dimensional convolution layer and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((64, 3, 23, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3242, -0.0299,  0.5053,  0.1944,  0.5568],\n",
       "          [ 0.4473, -0.7854,  0.0498,  0.6596,  0.5347],\n",
       "          [-1.1333, -0.4399, -0.2280,  0.8520, -0.2446],\n",
       "          [ 0.6046, -0.9033,  1.0315, -0.7924, -0.2479],\n",
       "          [ 0.2334,  0.8097, -0.6301,  0.5498,  0.3982]],\n",
       "\n",
       "         [[ 0.0656,  1.2447,  0.3868,  0.5862, -0.4954],\n",
       "          [ 0.0801, -1.0360,  0.4003,  0.1854,  0.4029],\n",
       "          [ 0.1834,  0.6223,  0.7189,  0.5508, -0.0173],\n",
       "          [-0.2326, -0.0663, -0.2472, -0.1819,  0.3045],\n",
       "          [ 0.0031, -0.0858, -0.2253, -0.4184,  0.8533]],\n",
       "\n",
       "         [[ 0.1784, -0.2754,  0.0795,  0.7774,  0.1876],\n",
       "          [-0.7676,  1.4561,  0.5549,  0.3622, -0.2183],\n",
       "          [ 0.2104, -0.4029,  0.1401, -0.9150,  0.6609],\n",
       "          [ 0.1210, -0.2161, -0.4463,  0.0390, -0.5558],\n",
       "          [-0.2484, -0.1759, -0.1680, -0.5349,  0.1346]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2439, -0.2298, -0.0422, -0.0121,  1.0363],\n",
       "          [-0.0490,  0.9998,  0.1759,  0.6432,  0.3420],\n",
       "          [ 0.5433,  1.1526, -0.0333, -0.3787, -0.2482],\n",
       "          [-0.5590,  0.1365,  0.2305,  0.0665, -0.2080],\n",
       "          [-0.0495,  0.5653,  0.5768,  0.2905,  0.1660]],\n",
       "\n",
       "         [[ 0.1913, -1.2312, -0.4164,  0.2820,  0.5262],\n",
       "          [-0.9636, -0.4117,  0.2904,  0.1426,  0.6132],\n",
       "          [-0.6008, -0.1777,  0.2959, -1.1843, -0.7547],\n",
       "          [-0.3876,  0.5117, -1.1214,  0.3848, -0.7622],\n",
       "          [-0.3942, -0.1685,  0.3799, -1.0618, -0.8406]],\n",
       "\n",
       "         [[ 0.0067, -1.0025, -0.6399, -0.2452,  0.6760],\n",
       "          [ 0.2286, -0.6154, -0.1143,  0.1126, -0.4477],\n",
       "          [ 0.4168, -1.6797, -0.1401, -0.5698,  0.5115],\n",
       "          [-0.3575,  0.5376,  0.2690, -0.3599, -0.7728],\n",
       "          [-0.2410, -0.5401,  0.0497, -0.2368, -0.9151]]],\n",
       "\n",
       "\n",
       "        [[[-0.6571, -0.3534, -0.0314, -1.0119, -0.6840],\n",
       "          [ 0.0549, -0.3394,  0.4668, -0.1272, -0.0359],\n",
       "          [ 0.1557, -0.3696,  0.3645, -0.3560,  0.1989],\n",
       "          [-0.2754, -0.0512, -0.0005,  0.1062, -0.7369],\n",
       "          [-0.0247,  0.3143,  0.8643, -0.2770,  0.0165]],\n",
       "\n",
       "         [[ 0.2326,  0.5966,  0.1156,  0.6559,  0.1725],\n",
       "          [-0.6660, -0.7192, -0.5065, -0.4706,  0.5399],\n",
       "          [-0.0225, -0.2298,  0.0565, -0.7880,  0.6401],\n",
       "          [-1.1779, -0.1232,  0.9596,  0.9609,  0.4163],\n",
       "          [ 0.0554,  0.1268,  1.0219, -0.0862,  0.3709]],\n",
       "\n",
       "         [[ 0.1918,  0.1924,  0.0387, -0.6253, -0.5544],\n",
       "          [ 0.4688,  0.0261,  0.5912, -0.4649,  0.1161],\n",
       "          [ 0.1842,  0.2974,  0.1609, -1.1874,  0.4468],\n",
       "          [-0.3637,  0.4600,  0.1055, -0.0951,  0.1817],\n",
       "          [-0.4533,  1.0204, -0.6889, -0.1158, -0.3020]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.7212, -0.8542, -0.7769, -0.4633, -0.1262],\n",
       "          [-0.0056, -0.2248,  0.7576,  0.1479,  0.1542],\n",
       "          [-0.1359, -0.0812, -0.8367,  0.5312, -0.4645],\n",
       "          [-0.8636,  0.1088,  0.2213,  0.0096, -0.4508],\n",
       "          [-0.1192,  0.5648, -0.5009, -0.3318, -0.6822]],\n",
       "\n",
       "         [[ 0.5123, -0.1828, -0.9423, -0.2247, -0.3913],\n",
       "          [ 0.1395,  0.7398,  0.0908, -0.1004,  0.5318],\n",
       "          [-0.3074,  0.0547, -0.2792, -0.2109, -0.0677],\n",
       "          [-0.0703,  0.1830, -0.1458, -0.7992,  0.3128],\n",
       "          [-1.0404, -0.7252, -0.6024, -0.2868, -0.7623]],\n",
       "\n",
       "         [[ 0.3475, -0.1284, -0.3267,  0.0551,  0.1613],\n",
       "          [ 0.3876, -0.4506, -0.2841,  0.7061, -0.2169],\n",
       "          [-1.0273, -0.4315,  0.1434,  0.3759, -0.2175],\n",
       "          [-0.1716, -0.4467, -0.4924, -0.3281, -0.5385],\n",
       "          [ 0.1849, -0.8454, -0.2214,  0.1480,  0.1806]]],\n",
       "\n",
       "\n",
       "        [[[-0.8757, -0.4228,  1.6272,  0.0201, -0.7858],\n",
       "          [-0.3905,  1.6962,  0.2395, -0.9093,  0.2375],\n",
       "          [-0.4244,  0.3691, -0.7957,  0.9569,  0.2159],\n",
       "          [ 0.3446,  0.4137, -1.3469,  0.5450,  0.3536],\n",
       "          [-0.1749,  0.7960,  0.4660,  0.6873,  0.3325]],\n",
       "\n",
       "         [[ 0.0541, -0.0848, -0.2923, -0.1413,  0.4964],\n",
       "          [ 0.3906, -1.5382, -0.5267, -0.1479, -0.5040],\n",
       "          [ 0.8032,  0.7018,  0.0064, -0.3758, -0.1199],\n",
       "          [ 0.5723, -0.0608,  0.3657,  0.1943, -0.1417],\n",
       "          [-0.3623, -1.0811, -0.3655, -0.5860, -0.2215]],\n",
       "\n",
       "         [[-0.5305, -0.1254,  0.7355,  0.1598, -0.4154],\n",
       "          [ 0.3982,  0.5284, -0.1968, -0.6825, -1.0018],\n",
       "          [ 0.0922, -0.0669, -1.2220,  0.4953,  0.5581],\n",
       "          [-0.8825,  0.6399, -0.6875, -0.0063,  0.4229],\n",
       "          [ 0.3040,  0.3165, -0.1380,  0.8083,  0.7475]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.9156,  0.5030, -0.8920, -0.7624,  0.1924],\n",
       "          [-0.1993,  0.6980,  0.2514,  0.4415,  0.5556],\n",
       "          [ 0.1710,  0.3441,  1.1712, -0.1442, -0.1898],\n",
       "          [ 0.7252,  0.1304, -0.6517, -1.2619, -0.6734],\n",
       "          [-0.1366, -0.0948,  0.0711, -0.8340, -0.0256]],\n",
       "\n",
       "         [[ 0.3414,  0.1043,  0.4854, -0.1536, -0.8321],\n",
       "          [ 1.1456, -0.5649,  0.4296,  0.6132,  0.0845],\n",
       "          [ 0.5139, -0.1671,  0.0592,  0.1718,  0.0395],\n",
       "          [ 0.5851, -0.5708, -0.8071,  0.2740,  0.1023],\n",
       "          [-0.4312, -0.4156, -0.6420,  0.3897,  0.3004]],\n",
       "\n",
       "         [[ 0.0253,  0.1295, -0.2280,  0.5625, -0.7371],\n",
       "          [-0.4442,  0.0972,  1.7321, -0.2316, -0.2642],\n",
       "          [ 0.2100, -0.5594, -0.3059,  0.1577, -0.1230],\n",
       "          [-0.3058,  0.0122, -0.4479, -0.0488,  0.6548],\n",
       "          [ 0.1676,  0.5300,  0.1943, -0.1476, -0.8643]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.7966, -0.4242,  0.8538, -0.6851, -0.4942],\n",
       "          [ 0.2930, -0.8884,  0.7949, -0.6797, -0.3781],\n",
       "          [-0.2033, -0.8580, -0.8015, -0.4896, -0.1755],\n",
       "          [ 0.0613,  1.0794, -0.7641, -0.5389, -0.2959],\n",
       "          [-0.3754,  0.6121, -0.2358, -0.4606,  0.3517]],\n",
       "\n",
       "         [[-0.8312, -0.6749,  0.0968,  0.3504, -0.2596],\n",
       "          [ 0.2157, -0.4167,  0.7391,  0.1985,  0.0175],\n",
       "          [ 0.3894,  0.3391, -0.7059,  0.4874,  0.5106],\n",
       "          [ 0.9315, -0.7052, -0.1501, -0.6483, -0.2909],\n",
       "          [ 0.5812,  0.1492,  0.0862, -0.2115, -0.5220]],\n",
       "\n",
       "         [[ 0.6190,  0.1982, -0.3150, -0.3408, -0.6060],\n",
       "          [ 0.5216, -0.5253, -0.5130,  0.1356,  0.0788],\n",
       "          [-0.2936,  0.5534,  0.0836, -0.0158, -0.1982],\n",
       "          [ 0.6888,  0.5498, -0.2602,  0.0476, -0.4288],\n",
       "          [ 0.4032, -0.0341,  0.4553, -0.0878,  0.6748]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1087, -0.2151,  0.6310,  1.1948, -0.3784],\n",
       "          [ 0.2782, -0.8989,  0.0629, -0.2495, -0.4718],\n",
       "          [-0.0272, -0.2677,  0.0422, -0.8893,  0.6221],\n",
       "          [ 0.4694, -0.1590,  0.0540,  0.2490, -0.5404],\n",
       "          [-0.4695, -0.1209,  0.1657, -0.9489,  0.3407]],\n",
       "\n",
       "         [[ 0.8476,  1.1947,  0.0600,  0.1476, -0.0401],\n",
       "          [ 0.1989, -0.6518, -1.1950,  0.8151, -0.8829],\n",
       "          [ 0.1249, -0.3520,  0.2793,  0.8775, -0.0312],\n",
       "          [-0.5269, -0.0416,  0.6746, -0.7350,  0.0921],\n",
       "          [-0.3014,  0.1238,  0.4248,  0.1761,  0.5285]],\n",
       "\n",
       "         [[-0.5327,  0.3156, -0.2128,  0.0177,  0.2082],\n",
       "          [ 0.2904,  0.4919, -0.2586,  0.0195, -0.4664],\n",
       "          [ 0.2400,  0.4302, -1.0333, -0.3501, -0.1615],\n",
       "          [-0.2740,  0.8029, -0.1622, -0.4328,  0.8029],\n",
       "          [-0.1295, -0.2030,  0.9292,  0.4758, -0.1472]]],\n",
       "\n",
       "\n",
       "        [[[-0.0064,  0.3742,  0.0352,  0.5567,  0.6030],\n",
       "          [ 0.0430, -0.8304,  0.0082,  0.2579,  0.1646],\n",
       "          [ 1.0888,  1.3701,  0.1326,  0.7836, -0.2995],\n",
       "          [ 0.4753,  0.7780, -0.1848, -0.2663, -0.4332],\n",
       "          [ 0.5845,  0.2613,  0.7390, -0.0891, -0.0869]],\n",
       "\n",
       "         [[ 0.2137,  0.0764,  0.3618,  0.3763,  0.0918],\n",
       "          [-0.4716, -0.8017, -0.5379, -0.8406,  0.5741],\n",
       "          [-0.9988, -1.5699,  0.5781, -1.4126,  0.0657],\n",
       "          [ 0.0806,  0.0678,  0.3985, -0.7682,  0.8456],\n",
       "          [ 0.2996, -0.6508, -0.4411, -0.0972, -0.3336]],\n",
       "\n",
       "         [[-0.2709,  0.2661,  0.8777,  0.6917, -0.5153],\n",
       "          [ 0.4356,  1.1294,  0.3845,  0.9162, -1.0426],\n",
       "          [-0.0919,  0.0117,  0.0646,  0.8827,  0.3129],\n",
       "          [-1.7051, -0.5800,  0.0984,  0.1139, -0.0984],\n",
       "          [ 0.3236, -0.2048,  0.0816,  0.1713,  0.0591]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0940, -0.0527, -0.8419,  0.0574,  0.0322],\n",
       "          [ 0.0411, -1.9644, -0.3008,  0.8891, -0.3412],\n",
       "          [-0.1700,  0.7521,  0.7587, -0.4667, -0.5176],\n",
       "          [-0.6511,  0.4890,  0.5686, -0.3709, -0.2793],\n",
       "          [ 0.4170,  0.0778, -0.1827, -0.2520, -0.4589]],\n",
       "\n",
       "         [[ 0.4110,  0.2955, -0.8832, -0.8239,  0.4284],\n",
       "          [-0.5964,  0.0655,  0.2380,  0.7850,  0.0664],\n",
       "          [ 0.1751,  0.4256,  0.3017,  0.2153,  0.3162],\n",
       "          [ 0.4477,  1.0566,  0.1186,  0.4856, -0.4421],\n",
       "          [ 0.0861,  0.4653,  1.1596, -0.8439,  0.4193]],\n",
       "\n",
       "         [[-0.8619,  0.1809, -0.5598, -0.2474,  0.0280],\n",
       "          [ 0.1656,  0.1061,  1.2827,  0.3676,  0.4183],\n",
       "          [-0.3804, -0.4383,  0.3094,  0.1637, -0.0691],\n",
       "          [ 0.6276,  0.3432, -0.0456,  0.0258,  0.5845],\n",
       "          [-0.1310,  0.3919,  1.7426, -1.3484, -0.5942]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4668,  0.5448,  0.2258,  0.3074,  0.6576],\n",
       "          [-0.1123, -0.2999,  0.0051,  0.7516,  0.4947],\n",
       "          [-0.1065,  1.1972,  0.4452, -0.4025, -0.5122],\n",
       "          [ 0.1492,  0.7048, -0.0683,  0.3981, -0.8671],\n",
       "          [ 0.1783, -0.1118,  0.9758,  0.1097,  0.1339]],\n",
       "\n",
       "         [[ 0.0327,  0.2246, -0.4236,  0.0049, -0.3590],\n",
       "          [ 0.3466, -0.7795,  0.3109,  0.1122,  0.6192],\n",
       "          [ 0.2151,  0.0978, -0.0193,  0.4029,  0.1164],\n",
       "          [ 0.5985,  0.6727, -0.1201,  0.6134, -0.4902],\n",
       "          [-0.4411, -0.2090, -0.2478,  0.0847, -0.1199]],\n",
       "\n",
       "         [[-0.0346,  0.6851,  0.3483, -0.1030, -0.8176],\n",
       "          [ 0.7550,  0.1554, -0.2347, -0.0150,  0.5828],\n",
       "          [ 0.0912, -0.0897,  1.0783,  0.3106, -0.8436],\n",
       "          [-0.4812,  0.8615,  0.8482, -0.2697,  0.2243],\n",
       "          [-0.1254, -0.0882,  0.8575, -0.2611, -0.0909]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4847, -0.0291,  0.7915, -0.0242,  0.3704],\n",
       "          [-0.9039,  0.3429, -0.1376,  0.6821, -0.6838],\n",
       "          [ 0.4236,  0.2721, -0.2573,  0.5410,  0.5332],\n",
       "          [-0.4053, -0.5163, -0.1527, -0.4149,  0.5394],\n",
       "          [-0.3800, -0.1209,  0.0987, -0.2694, -0.8929]],\n",
       "\n",
       "         [[ 0.2071, -0.2221, -0.2991,  0.8207, -0.3680],\n",
       "          [-0.4423, -1.4749,  0.1212, -0.4328,  0.0423],\n",
       "          [-0.3433, -0.5115,  0.0316, -0.1746, -0.6798],\n",
       "          [-0.3626,  0.4987, -0.0299, -0.7413,  0.1683],\n",
       "          [-0.4609, -0.1044,  0.0078,  0.0437, -0.1275]],\n",
       "\n",
       "         [[-0.7878, -0.3444,  1.0454, -0.6782, -0.0888],\n",
       "          [-0.5603, -0.5530, -0.6292, -0.1675, -0.2660],\n",
       "          [ 0.0382, -0.5936,  0.0449,  0.4647, -0.8693],\n",
       "          [-0.4562, -0.7709, -0.2071,  0.1564, -0.2575],\n",
       "          [-0.3176, -0.3355,  0.0011, -0.0426, -0.5281]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_dimensional_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2)\n",
    "two_dimensional_conv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the same convolution with an all-zero filter. Try to catch the difference between ```torch.nn``` layers and ```torch.nn.functional``` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_conv_result = F.conv2d(input=X, weight=torch.zeros(64, 3, 11, 11), stride=4, padding=2)\n",
    "zero_conv_result_pool = F.max_pool2d(zero_conv_result, kernel_size=3, stride=2)\n",
    "zero_conv_result_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```nn.Sequential```, we can define simple models that do not require much setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8375, 0.3527],\n",
       "          [0.0991, 0.4620]],\n",
       "\n",
       "         [[0.7641, 0.7641],\n",
       "          [0.7641, 0.7641]],\n",
       "\n",
       "         [[0.7477, 0.6807],\n",
       "          [0.7477, 0.5126]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.2538, 1.2538],\n",
       "          [0.7319, 0.3746]],\n",
       "\n",
       "         [[0.6574, 0.6888],\n",
       "          [0.4160, 0.6888]],\n",
       "\n",
       "         [[0.3700, 1.0302],\n",
       "          [0.3234, 0.3940]]],\n",
       "\n",
       "\n",
       "        [[[0.7115, 0.8124],\n",
       "          [0.9468, 0.9468]],\n",
       "\n",
       "         [[0.8445, 0.6777],\n",
       "          [0.7232, 0.7027]],\n",
       "\n",
       "         [[0.6984, 0.8395],\n",
       "          [0.5988, 0.8113]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.4136, 0.1237],\n",
       "          [1.0771, 0.4987]],\n",
       "\n",
       "         [[1.7439, 1.7439],\n",
       "          [0.5152, 1.2221]],\n",
       "\n",
       "         [[1.1078, 1.1078],\n",
       "          [0.8472, 1.0773]]],\n",
       "\n",
       "\n",
       "        [[[0.8966, 0.8966],\n",
       "          [0.8447, 0.7951]],\n",
       "\n",
       "         [[0.7645, 0.8031],\n",
       "          [0.8775, 0.8775]],\n",
       "\n",
       "         [[1.5547, 1.5547],\n",
       "          [1.5547, 1.5547]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.4454, 0.4585],\n",
       "          [0.3934, 0.4585]],\n",
       "\n",
       "         [[0.4848, 0.4777],\n",
       "          [0.4848, 0.1580]],\n",
       "\n",
       "         [[0.2131, 0.2974],\n",
       "          [0.8671, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.5815, 0.7144],\n",
       "          [0.6803, 1.2632]],\n",
       "\n",
       "         [[0.7312, 0.4918],\n",
       "          [0.7312, 0.4918]],\n",
       "\n",
       "         [[0.8275, 0.4662],\n",
       "          [0.5250, 0.6323]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.9713, 0.9713],\n",
       "          [0.5788, 0.3764]],\n",
       "\n",
       "         [[1.2519, 1.5961],\n",
       "          [0.6783, 0.2983]],\n",
       "\n",
       "         [[1.1620, 0.9742],\n",
       "          [1.0503, 0.4151]]],\n",
       "\n",
       "\n",
       "        [[[0.7042, 0.7042],\n",
       "          [0.6348, 0.9640]],\n",
       "\n",
       "         [[1.5325, 0.6191],\n",
       "          [1.0976, 0.5261]],\n",
       "\n",
       "         [[0.3277, 0.4364],\n",
       "          [1.2143, 0.5932]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.2234, 0.7796],\n",
       "          [0.4095, 0.7796]],\n",
       "\n",
       "         [[0.3352, 0.1429],\n",
       "          [0.5176, 0.6121]],\n",
       "\n",
       "         [[0.7352, 0.4750],\n",
       "          [0.7352, 0.6004]]],\n",
       "\n",
       "\n",
       "        [[[1.3130, 1.3130],\n",
       "          [0.5227, 0.4983]],\n",
       "\n",
       "         [[0.4637, 0.6155],\n",
       "          [1.0232, 1.1000]],\n",
       "\n",
       "         [[0.8597, 0.9779],\n",
       "          [0.9866, 0.1822]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.3582, 1.2760],\n",
       "          [1.3582, 0.5196]],\n",
       "\n",
       "         [[0.9299, 0.9299],\n",
       "          [0.9663, 0.9663]],\n",
       "\n",
       "         [[0.7728, 1.0988],\n",
       "          [0.6619, 0.9817]]]], grad_fn=<MaxPool2DWithIndicesBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2)\n",
    ")\n",
    "\n",
    "simple_model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Models\n",
    "\n",
    "To create custom models, we define a class that inherits ```torch.nn.Module```. Then, all we need to define is the ```__init__``` function and the ```forward``` function.\n",
    "\n",
    "Generally speaking, we define the layers and their initialization in ```__init__``` and define their connections in ```forward```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(64*2*2, num_classes)\n",
    "        \n",
    "        self.convs = [nn.Conv]\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if type(m) in [nn.Conv2d, nn.Linear]:\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                m.bias.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = x.view(-1, 64*2*2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNet()\n",
    "model(X).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
